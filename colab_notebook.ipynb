{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0_pathway.md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "first we convert UCF101 dataset to nframes, basically extracting frames from each video (at 1 fps)\n",
    "\n",
    "```\n",
    "/utils/avi2jpg.py\n",
    "```\n",
    "\n",
    "[UCF101] --> [UCF101_n_frames]\n",
    "now [UCF101] has no dependancies\n",
    "\n",
    "then we write n-frames data for each video folder\n",
    "\n",
    "```\n",
    "/utils/n_frames_ucf101.py\n",
    "```\n",
    "\n",
    "[UCF101_n_frames] <--->\n",
    "still has depenedancies\n",
    "\n",
    "now we have completed Data Loading and have UCF101_n_frames\n",
    "\n",
    "next we need to apply some basic preprocessing steps on it\n",
    "\n",
    "```\n",
    "/dataloaders/ucf_dataset-persistent.py\n",
    "```\n",
    "\n",
    "[UCF101_n_frames], [all_videos.txt], [classInd.txt] --> [UCF-preprocessed]\n",
    "now [UCF101_n_frames] has no dependancies\n",
    "we have passed it file containing names of all videos rather than one file from ucfTrainTestList\n",
    "we get UCF-preprocessed\n",
    "\n",
    "next we apply ROI techiniques on it\n",
    "we apply a pretrained yolo model to detect people in the dataset and draw the bounding boxes\n",
    "\n",
    "```\n",
    "/model-predict-opti_final.py\n",
    "```\n",
    "\n",
    "[UCF-preprocessed] --> [UCF_obj_detected]\n",
    "[UCF-preprocessed] still has dependancies\n",
    "bboxes are stored in UCF_obj_detected\n",
    "\n",
    "next we need to alter the generated labels so they represent actions instead of objects\n",
    "we are also combining the bboxes and adding padding\n",
    "\n",
    "```\n",
    "/action_labelling_roi.py \n",
    "```\n",
    "\n",
    "[UCF_obj_detected] --> [UCF_action_labelled_roi]\n",
    "now [UCF_obj_detected] has no dependancies\n",
    "\n",
    "# TODO\n",
    "\n",
    "multi line testing\n",
    "\n",
    "we get updated labels in UCF_action_labelled_roi\n",
    "\n",
    "next we need to split the datasets into train test and val\n",
    "\n",
    "```\n",
    "/train_test_splitting_final.py\n",
    "```\n",
    "\n",
    "[UCF_action_labelled_roi], [UCF-preprocessed] --> [train-data]\n",
    "now both datasets have no dependancies\n",
    "\n",
    "it takes labels from \"UCF_action_labelled_roi\" and images from \"UCF-preprocessed\"\n",
    "it splits them\n",
    "70% train\n",
    "15% test\n",
    "15% validation\n",
    "\n",
    "now we have our training data in /train-data\n",
    "\n",
    "next we will train a custom yolo model on the training data\n",
    "\n",
    "```\n",
    "/train-data/model-train.py\n",
    "```\n",
    "\n",
    "[train-data], [ucf101.yaml] --> [best.pt]\n",
    "now [train-data] has no dependancies, but it does contain model insights\n",
    "we will have our best.pt model in /train-data/runs\n",
    "\n",
    "Thats it! we have our custom trained model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1_frame_extraction.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "#frames per second to extract\n",
    "FPS_RATE = 1\n",
    "\n",
    "#paths\n",
    "dir_path = 'Dataset/UCF-101/'\n",
    "dst_dir_path = 'Dataset/UCF101_n_frames'\n",
    "\n",
    "\n",
    "for class_name in os.listdir(dir_path):\n",
    "    class_path = os.path.join(dir_path, class_name)\n",
    "    if not os.path.isdir(class_path):\n",
    "        continue\n",
    "\n",
    "    dst_class_path = os.path.join(dst_dir_path, class_name)\n",
    "    if not os.path.exists(dst_class_path):\n",
    "        os.mkdir(dst_class_path)\n",
    "\n",
    "    for file_name in os.listdir(class_path):\n",
    "        if '.avi' not in file_name:\n",
    "            continue\n",
    "        name, ext = os.path.splitext(file_name)\n",
    "    \n",
    "        dst_directory_path = os.path.join(dst_class_path, name)\n",
    "\n",
    "        video_file_path = os.path.join(class_path, file_name)\n",
    "        try:\n",
    "            if os.path.exists(dst_directory_path):\n",
    "                if not os.path.exists(os.path.join(dst_directory_path, 'image_00001.jpg')):\n",
    "                    subprocess.call('rm -r \\\"{}\\\"'.format(dst_directory_path), shell=True)\n",
    "                    print('remove {}'.format(dst_directory_path))\n",
    "                    os.mkdir(dst_directory_path)\n",
    "            \n",
    "                else:\n",
    "                    continue\n",
    "            else:\n",
    "                os.mkdir(dst_directory_path)\n",
    "        except:\n",
    "            print(dst_directory_path)\n",
    "            continue\n",
    "        cmd = 'ffmpeg -i \\\"{}\\\" -vf \"fps={},scale=-1:240\" \\\"{}/image_%05d.jpg\\\"'.format(video_file_path, FPS_RATE, dst_directory_path)\n",
    "    \n",
    "        print(cmd)\n",
    "        subprocess.call(cmd, shell=True)\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2_writing_frame_data.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import os\n",
    "\n",
    "dir_path = './Dataset/UCF101_n_frames'\n",
    "\n",
    "for class_name in os.listdir(dir_path):\n",
    "    class_path = os.path.join(dir_path, class_name)\n",
    "    if not os.path.isdir(class_path):\n",
    "        continue\n",
    "\n",
    "    for file_name in os.listdir(class_path):\n",
    "        video_dir_path = os.path.join(class_path, file_name)\n",
    "        image_indices = []\n",
    "        for image_file_name in os.listdir(video_dir_path):\n",
    "            if 'image' not in image_file_name:\n",
    "                continue\n",
    "            image_indices.append(int(image_file_name[6:11]))\n",
    "\n",
    "        if len(image_indices) == 0:\n",
    "            print('no image files', video_dir_path)\n",
    "            n_frames = 0\n",
    "        else:\n",
    "            image_indices.sort(reverse=True)\n",
    "            n_frames = image_indices[0]\n",
    "            print(video_dir_path, n_frames)\n",
    "        with open(os.path.join(video_dir_path, 'n_frames'), 'w') as dst_file:\n",
    "            dst_file.write(str(n_frames))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3_data_preprocessing.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "import cv2\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "\n",
    "\n",
    "root_dir = './'\n",
    "root_list = root_dir + 'Dataset/UCF101_n_frames/'\n",
    "info_list = root_dir + 'all_videos.txt'\n",
    "save_dir = root_dir + 'Dataset/UCF-preprocessed'\n",
    "class_dir = root_dir + 'classInd.txt'\n",
    "\n",
    "#frames per video\n",
    "CLIP_LENGTH = 8\n",
    "\n",
    "\n",
    "class ClipSubstractMean(object):\n",
    "    def __init__(self, b=104, g=117, r=123):\n",
    "        self.means = np.array((101.4, 97.7, 90.2))  # B=90.25, G=97.66, R=101.41\n",
    "\n",
    "    def __call__(self, buffer):\n",
    "        new_buffer = buffer - self.means\n",
    "        return new_buffer\n",
    "\n",
    "\n",
    "class RandomCrop(object):\n",
    "    \"\"\"Crop randomly the image in a sample.\n",
    "\n",
    "    Args:\n",
    "        output_size (tuple or int): Desired output size. If int, square crop\n",
    "            is made.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, output_size=(112, 112)):\n",
    "        assert isinstance(output_size, (int, tuple))\n",
    "        if isinstance(output_size, int):\n",
    "            self.output_size = (output_size, output_size)\n",
    "        else:\n",
    "            assert len(output_size) == 2\n",
    "            self.output_size = output_size\n",
    "\n",
    "    def __call__(self, buffer):\n",
    "        h, w = buffer.shape[1], buffer.shape[2]\n",
    "        new_h, new_w = self.output_size\n",
    "\n",
    "        top = np.random.randint(0, h - new_h)\n",
    "        left = np.random.randint(0, w - new_w)\n",
    "\n",
    "        new_buffer = np.zeros((buffer.shape[0], new_h, new_w, 3))\n",
    "        for i in range(buffer.shape[0]):\n",
    "            image = buffer[i, :, :, :]\n",
    "            image = image[top: top + new_h, left: left + new_w]\n",
    "            new_buffer[i, :, :, :] = image\n",
    "\n",
    "        return new_buffer\n",
    "\n",
    "\n",
    "class CenterCrop(object):\n",
    "    \"\"\"Crop the image in a sample at the center.\n",
    "\n",
    "    Args:\n",
    "        output_size (tuple or int): Desired output size. If int, square crop\n",
    "            is made.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, output_size=(112, 112)):\n",
    "        assert isinstance(output_size, (int, tuple))\n",
    "        if isinstance(output_size, int):\n",
    "            self.output_size = (output_size, output_size)\n",
    "        else:\n",
    "            assert len(output_size) == 2\n",
    "            self.output_size = output_size\n",
    "\n",
    "    def __call__(self, buffer):\n",
    "        h, w = buffer.shape[1], buffer.shape[2]\n",
    "        new_h, new_w = self.output_size\n",
    "\n",
    "        top = int(round(h - new_h) / 2.)\n",
    "        left = int(round(w - new_w) / 2.)\n",
    "\n",
    "        new_buffer = np.zeros((buffer.shape[0], new_h, new_w, 3))\n",
    "        for i in range(buffer.shape[0]):\n",
    "            image = buffer[i, :, :, :]\n",
    "            image = image[top: top + new_h, left: left + new_w]\n",
    "            new_buffer[i, :, :, :] = image\n",
    "\n",
    "        return new_buffer\n",
    "\n",
    "\n",
    "class RandomHorizontalFlip(object):\n",
    "    \"\"\"Horizontally flip the given Images randomly with a given probability.\n",
    "\n",
    "    Args:\n",
    "        p (float): probability of the image being flipped. Default value is 0.5\n",
    "    \"\"\"\n",
    "\n",
    "    def __call__(self, buffer):\n",
    "        if np.random.random() < 0.5:\n",
    "            for i, frame in enumerate(buffer):\n",
    "                buffer[i] = cv2.flip(frame, flipCode=1)\n",
    "\n",
    "        return buffer\n",
    "\n",
    "\n",
    "class ToTensor(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "\n",
    "    def __call__(self, buffer):\n",
    "        # swap color axis because\n",
    "        # numpy image: batch_size x H x W x C\n",
    "        # torch image: batch_size x C X H X W\n",
    "        img = torch.from_numpy(buffer.transpose((3, 0, 1, 2)))\n",
    "\n",
    "        return img.float().div(255)\n",
    "\n",
    "\n",
    "class UCFDataset(Dataset):\n",
    "    r\"\"\"A Dataset for a folder of videos. Expects the directory structure to be\n",
    "    directory->[train/val/test]->[class labels]->[videos]. Initializes with a list\n",
    "    of all file names, along with an array of labels, with label being automatically\n",
    "    inferred from the respective folder names.\n",
    "\n",
    "        Args:\n",
    "            root_dir (str): path to n_frames_jpg folders.\n",
    "            info_list (str): path to annotation file.\n",
    "            split(str): whether create trainset. Default='train'.\n",
    "            clip_len (int): Determines how many frames are there in each clip. Defaults to 16.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, class_dir, root_dir, info_list, clip_len=16, save_dir=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.clip_len = clip_len\n",
    "        self.landmarks_frame = pd.read_csv(info_list, delimiter=' ', header=None)\n",
    "        self.label_class_map = {}\n",
    "        with open(class_dir) as f:\n",
    "            for line in f:\n",
    "                line=line.strip('\\n').split(' ')\n",
    "                self.label_class_map[line[1]] = line[0]\n",
    "        self.transform = transforms.Compose(\n",
    "            [ClipSubstractMean(),\n",
    "                RandomCrop(),\n",
    "                RandomHorizontalFlip(),\n",
    "                ToTensor()])\n",
    "        # The following three parameters are chosen as described in the paper section 4.1\n",
    "        self.resize_height = 128\n",
    "        self.resize_width = 171\n",
    "        self.crop_size = 112\n",
    "\n",
    "    \n",
    "        self.save_dir = save_dir\n",
    "        print(save_dir)\n",
    "        if self.save_dir is not None:\n",
    "            os.makedirs(self.save_dir, exist_ok=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.landmarks_frame)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Loading and preprocessing.\n",
    "        video_path = self.landmarks_frame.iloc[index, 0]\n",
    "        # labels [0,100]\n",
    "        if self.landmarks_frame.shape[1] == 2:\n",
    "            labels = self.landmarks_frame.iloc[index, 1] - 1\n",
    "        else:\n",
    "            classes = video_path.split('/')[0]\n",
    "            labels = int(self.label_class_map[classes]) - 1\n",
    "        buffer = self.get_resized_frames_per_video(video_path)\n",
    "\n",
    "        if self.transform:\n",
    "            buffer = self.transform(buffer)\n",
    "\n",
    "        return buffer, torch.from_numpy(np.array(labels))\n",
    "\n",
    "    def get_resized_frames_per_video(self, video_path):\n",
    "        slash_rows = video_path.split('.')\n",
    "        dir_name = slash_rows[0]\n",
    "        video_jpgs_path = os.path.join(self.root_dir, dir_name)\n",
    "\n",
    "        # Read the number of frames from the n_frames file\n",
    "        data = pd.read_csv(os.path.join(video_jpgs_path, 'n_frames'), delimiter=' ', header=None)\n",
    "        frame_count = data[0][0]\n",
    "\n",
    "        # Initialize an array to store all frames\n",
    "        video_x = np.empty((self.clip_len, self.resize_height, self.resize_width, 3), np.dtype('float32'))\n",
    "        \n",
    "        print(video_jpgs_path)\n",
    "\n",
    "        for i in range(self.clip_len):\n",
    "            # Compute the frame number based on the clip length\n",
    "            frame_number = (i * frame_count) // self.clip_len + 1\n",
    "\n",
    "            # Generate the image filename based on the frame number\n",
    "            s = \"%05d\" % frame_number\n",
    "            image_name = 'image_' + s + '.jpg'\n",
    "            image_path = os.path.join(video_jpgs_path, image_name)\n",
    "\n",
    "            if os.path.exists(image_path):\n",
    "                # Read and resize the image\n",
    "                tmp_image = cv2.imread(image_path)\n",
    "                tmp_image = cv2.resize(tmp_image, (self.resize_width, self.resize_height))\n",
    "                tmp_image = np.array(tmp_image).astype(np.float64)\n",
    "                tmp_image = tmp_image[:, :, ::-1]  # BGR -> RGB\n",
    "\n",
    "                # Store the frame in the array\n",
    "                video_x[i, :, :, :] = tmp_image\n",
    "            \n",
    "            if self.save_dir is not None:\n",
    "                # Save the preprocessed frame to the new directory\n",
    "                save_image_path = os.path.join(self.save_dir, dir_name)\n",
    "                \n",
    "                # Ensure the directory exists, create if necessary\n",
    "                os.makedirs(save_image_path, exist_ok=True)\n",
    "                \n",
    "                # Append the file name to the directory path\n",
    "                save_image_path = os.path.join(save_image_path, f'image_{i:05d}.jpg')\n",
    "\n",
    "                \n",
    "                # print(save_image_path, \"saved\")\n",
    "                cv2.imwrite(save_image_path, tmp_image)\n",
    "\n",
    "        return video_x\n",
    "    \n",
    "    \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    test_dataloader = DataLoader(\n",
    "        UCFDataset(\n",
    "                class_dir=class_dir,\n",
    "                root_dir=root_list,\n",
    "                info_list=info_list,\n",
    "                clip_len=CLIP_LENGTH,\n",
    "                save_dir=save_dir),\n",
    "        batch_size=8, shuffle=True, num_workers=0\n",
    "    )\n",
    "\n",
    "    for i_batch, (images, targets) in enumerate(test_dataloader):\n",
    "        print(\"-----------------Batch: \", i_batch)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4_object_pose_detection.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#performing object detection, pose estimation\n",
    "from ultralytics import YOLO\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# Define the root directory\n",
    "root_dir = './Dataset'\n",
    "processed_dir_name = \"/UCF-preprocessed\"\n",
    "output_dir_name = \"/UCF_obj_detected\"\n",
    "\n",
    "processed_dir = root_dir + processed_dir_name\n",
    "\n",
    "# Load a pretrained YOLOv8n model\n",
    "model = YOLO('yolov8n-pose.pt')\n",
    "\n",
    "# Walk through all files in the directory\n",
    "for dirpath, dirnames, filenames in os.walk(processed_dir):\n",
    "    \n",
    "    print(\"dirpath: \", dirpath)\n",
    "    print(\"dirnames: \", dirnames)\n",
    "    print(\"filenames: \", filenames)\n",
    "        \n",
    "    image_extensions = ['.jpg', '.jpeg', '.png', '.gif']\n",
    "    image_files = [file for file in glob.glob(os.path.join(dirpath, '*')) if os.path.splitext(file)[1].lower() in image_extensions]\n",
    "    if len(image_files) == 0:\n",
    "        continue\n",
    "\n",
    "    # Create the output directory for the current action\n",
    "    output_dir = dirpath.replace(processed_dir_name, output_dir)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "\n",
    "    print(\"\")\n",
    "    print(\"\")\n",
    "    model.predict(source=dirpath, conf=0.5, save_txt=True, project=output_dir)\n",
    "    print(\"completed model run on \", dirpath)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5_action_labelling_roi_processing.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\"\"\"\n",
    "has to be run BEFORE train-test-val splitting\n",
    "because in the splitting, action association is lost\n",
    "\"\"\"\n",
    "\n",
    "#either ROI or pose estimation\n",
    "APPLY_ROI = False\n",
    "\n",
    "# Define the directory paths\n",
    "root_dir = \"./Dataset\"\n",
    "input_dir = root_dir + \"/UCF_obj_detected\"\n",
    "output_dir = root_dir + \"/UCF_action_labelled_roi\"\n",
    "\n",
    "#%% functions\n",
    "\n",
    "actions = {\n",
    "    \"ApplyEyeMakeup\": 0,\n",
    "    \"ApplyLipstick\": 1,\n",
    "    \"Archery\": 2,\n",
    "    \"BabyCrawling\": 3,\n",
    "    \"BalanceBeam\": 4,\n",
    "    \"BandMarching\": 5,\n",
    "    \"BaseballPitch\": 6,\n",
    "    \"Basketball\": 7,\n",
    "    \"BasketballDunk\": 8,\n",
    "    \"BenchPress\": 9,\n",
    "    \"Biking\": 10,\n",
    "    \"Billiards\": 11,\n",
    "    \"BlowDryHair\": 12,\n",
    "    \"BlowingCandles\": 13,\n",
    "    \"BodyWeightSquats\": 14,\n",
    "    \"Bowling\": 15,\n",
    "    \"BoxingPunchingBag\": 16,\n",
    "    \"BoxingSpeedBag\": 17,\n",
    "    \"BreastStroke\": 18,\n",
    "    \"BrushingTeeth\": 19,\n",
    "    \"CleanAndJerk\": 20,\n",
    "    \"CliffDiving\": 21,\n",
    "    \"CricketBowling\": 22,\n",
    "    \"CricketShot\": 23,\n",
    "    \"CuttingInKitchen\": 24,\n",
    "    \"Diving\": 25,\n",
    "    \"Drumming\": 26,\n",
    "    \"Fencing\": 27,\n",
    "    \"FieldHockeyPenalty\": 28,\n",
    "    \"FloorGymnastics\": 29,\n",
    "    \"FrisbeeCatch\": 30,\n",
    "    \"FrontCrawl\": 31,\n",
    "    \"GolfSwing\": 32,\n",
    "    \"Haircut\": 33,\n",
    "    \"HammerThrow\": 34,\n",
    "    \"Hammering\": 35,\n",
    "    \"HandstandPushups\": 36,\n",
    "    \"HandstandWalking\": 37,\n",
    "    \"HeadMassage\": 38,\n",
    "    \"HighJump\": 39,\n",
    "    \"HorseRace\": 40,\n",
    "    \"HorseRiding\": 41,\n",
    "    \"HulaHoop\": 42,\n",
    "    \"IceDancing\": 43,\n",
    "    \"JavelinThrow\": 44,\n",
    "    \"JugglingBalls\": 45,\n",
    "    \"JumpRope\": 46,\n",
    "    \"JumpingJack\": 47,\n",
    "    \"Kayaking\": 48,\n",
    "    \"Knitting\": 49,\n",
    "    \"LongJump\": 50,\n",
    "    \"Lunges\": 51,\n",
    "    \"MilitaryParade\": 52,\n",
    "    \"Mixing\": 53,\n",
    "    \"MoppingFloor\": 54,\n",
    "    \"Nunchucks\": 55,\n",
    "    \"ParallelBars\": 56,\n",
    "    \"PizzaTossing\": 57,\n",
    "    \"PlayingCello\": 58,\n",
    "    \"PlayingDaf\": 59,\n",
    "    \"PlayingDhol\": 60,\n",
    "    \"PlayingFlute\": 61,\n",
    "    \"PlayingGuitar\": 62,\n",
    "    \"PlayingPiano\": 63,\n",
    "    \"PlayingSitar\": 64,\n",
    "    \"PlayingTabla\": 65,\n",
    "    \"PlayingViolin\": 66,\n",
    "    \"PoleVault\": 67,\n",
    "    \"PommelHorse\": 68,\n",
    "    \"PullUps\": 69,\n",
    "    \"Punch\": 70,\n",
    "    \"PushUps\": 71,\n",
    "    \"Rafting\": 72,\n",
    "    \"RockClimbingIndoor\": 73,\n",
    "    \"RopeClimbing\": 74,\n",
    "    \"Rowing\": 75,\n",
    "    \"SalsaSpin\": 76,\n",
    "    \"ShavingBeard\": 77,\n",
    "    \"Shotput\": 78,\n",
    "    \"SkateBoarding\": 79,\n",
    "    \"Skiing\": 80,\n",
    "    \"Skijet\": 81,\n",
    "    \"SkyDiving\": 82,\n",
    "    \"SoccerJuggling\": 83,\n",
    "    \"SoccerPenalty\": 84,\n",
    "    \"StillRings\": 85,\n",
    "    \"SumoWrestling\": 86,\n",
    "    \"Surfing\": 87,\n",
    "    \"Swing\": 88,\n",
    "    \"TableTennisShot\": 89,\n",
    "    \"TaiChi\": 90,\n",
    "    \"TennisSwing\": 91,\n",
    "    \"ThrowDiscus\": 92,\n",
    "    \"TrampolineJumping\": 93,\n",
    "    \"Typing\": 94,\n",
    "    \"UnevenBars\": 95,\n",
    "    \"VolleyballSpiking\": 96,\n",
    "    \"WalkingWithDog\": 97,\n",
    "    \"WallPushups\": 98,\n",
    "    \"WritingOnBoard\": 99,\n",
    "    \"YoYo\": 100\n",
    "}\n",
    "\n",
    "\n",
    "# overwrite classes in labels with class corresponding to action_name\n",
    "\n",
    "# Calculate the ROI for a set of bounding boxes\n",
    "def calculate_roi(bboxes):\n",
    "    min_x = float('inf')\n",
    "    min_y = float('inf')\n",
    "    max_x = float('-inf')\n",
    "    max_y = float('-inf')\n",
    "\n",
    "    roi_bboxes = []\n",
    "\n",
    "    # Find the minimum and maximum coordinates\n",
    "    for bbox in bboxes:\n",
    "        x, y, w, h = bbox\n",
    "        min_x = min(min_x, x)\n",
    "        min_y = min(min_y, y)\n",
    "        max_x = max(max_x, x + w)\n",
    "        max_y = max(max_y, y + h)\n",
    "\n",
    "        # Calculate the ROI coordinates\n",
    "        roi_x = min_x\n",
    "        roi_y = min_y\n",
    "        roi_w = max_x - min_x\n",
    "        roi_h = max_y - min_y\n",
    "\n",
    "        roi_bboxes.append((roi_x, roi_y, roi_w, roi_h))\n",
    "\n",
    "    return roi_bboxes\n",
    "\n",
    "# Add padding to a set of bounding boxes\n",
    "def add_padding(bboxes, padding_percent = 0.1):\n",
    "    padded_bboxes = []\n",
    "\n",
    "    # Calculate the padding values\n",
    "    padding_x = padding_percent * bboxes[0][2]\n",
    "    padding_y = padding_percent * bboxes[0][3]\n",
    "\n",
    "    # Add padding to each bounding box\n",
    "    for bbox in bboxes:\n",
    "        x, y, w, h = bbox\n",
    "        padded_x = x - padding_x\n",
    "        padded_y = y - padding_y\n",
    "        padded_w = w + 2 * padding_x\n",
    "        padded_h = h + 2 * padding_y\n",
    "        padded_bboxes.append((padded_x, padded_y, padded_w, padded_h))\n",
    "\n",
    "    return padded_bboxes\n",
    "\n",
    "#%%\n",
    "\"\"\"\n",
    "applied on Dataset/UCF_obj_detected\n",
    "stores in Dataset/UCF_action_labelled\n",
    "\n",
    "-- labels dir\n",
    "../Dataset/UCF_obj_detected/{action_name}/{video_name}/predict/labels/{frame_name}.txt\n",
    "\n",
    "take each of these labels, replace the first number (class id) with class from names[action_name]\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "#%%\n",
    "\n",
    "# Ensure output directory exists\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Iterate over the action directories\n",
    "for action_name in os.listdir(input_dir):\n",
    "    action_dir = os.path.join(input_dir, action_name)\n",
    "    if not os.path.isdir(action_dir):\n",
    "        continue\n",
    "\n",
    "    # Iterate over the video directories\n",
    "    for video_name in os.listdir(action_dir):\n",
    "        video_dir = os.path.join(action_dir, video_name)\n",
    "        if not os.path.isdir(video_dir):\n",
    "            continue\n",
    "\n",
    "        print(f\"Processing {video_name}...\")\n",
    "\n",
    "        # Iterate over the label files\n",
    "        labels_dir = os.path.join(video_dir, \"predict\", \"labels\")\n",
    "        for frame_name in os.listdir(labels_dir):\n",
    "            label_file = os.path.join(labels_dir, frame_name)\n",
    "            if not os.path.isfile(label_file):\n",
    "                continue\n",
    "\n",
    "            # Read the label file\n",
    "            with open(label_file, \"r\") as f:\n",
    "                lines = f.readlines()\n",
    "\n",
    "            # Replace the class id with the action id\n",
    "            action_id = actions[action_name]\n",
    "            for i in range(len(lines)):\n",
    "                class_id, *rest = lines[i].split()\n",
    "                lines[i] = f\"{action_id} {' '.join(rest)}\"\n",
    "\n",
    "            bboxes = [(float(bbox.split()[1]), float(bbox.split()[2]), float(bbox.split()[3]), float(bbox.split()[4])) for bbox in lines]\n",
    "\n",
    "            if APPLY_ROI:\n",
    "                roi_bboxes = calculate_roi(bboxes)\n",
    "                padded_bboxes = add_padding(roi_bboxes)\n",
    "            else:\n",
    "                padded_bboxes = add_padding(bboxes)\n",
    "\n",
    "            # Convert the padded bounding boxes back to lines\n",
    "            mod_lines = [f\"{action_id} {bbox[0]} {bbox[1]} {bbox[2]} {bbox[3]}\\n\" for bbox in padded_bboxes]\n",
    "\n",
    "            # Write the modified label file to the output directory\n",
    "            output_subdir = os.path.join(output_dir, action_name, video_name, \"predict\", \"labels\")\n",
    "            os.makedirs(output_subdir, exist_ok=True)\n",
    "            output_file = os.path.join(output_subdir, frame_name)\n",
    "            with open(output_file, \"w\") as f:\n",
    "                f.writelines(mod_lines)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6_data_train_test_splitting.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "1- output format for yolo training\n",
    "\n",
    "train_dir = /workspaces/video-dataset-preprocess/train-data\n",
    "^has results\n",
    "\n",
    "data splitted in 3 folders:\n",
    "train_dir/train\n",
    "train_dir/test\n",
    "train_dir/val\n",
    "\n",
    "each folder:\n",
    "./images\n",
    "./labels\n",
    "\n",
    "./images takes the images from UCF-preprocessed\n",
    "./labels takes the labels from UCF_obj_detected\n",
    "\n",
    "hierarchy of UCF-preprocessed:\n",
    "./action_name/video_name/images.jpg\n",
    "\n",
    "hierarchy of UCF_obj_detected:\n",
    "./action_name/video_name/predict/labels/label.txt\n",
    "\n",
    "\n",
    "70% training\n",
    "15% testing\n",
    "15% validation\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "# Define the paths\n",
    "root_dir = \"./Dataset\"\n",
    "train_dir = root_dir + \"/train-data\"\n",
    "ucf_action_labelled_roi_dir_label = root_dir + \"/UCF_action_labelled_roi\"\n",
    "ucf_preprocessed_dir_img = root_dir + \"/UCF_preprocessed\"\n",
    "\n",
    "# Create train, test, and validation directories\n",
    "train_data_dir = os.path.join(train_dir, \"train\")\n",
    "test_data_dir = os.path.join(train_dir, \"test\")\n",
    "val_data_dir = os.path.join(train_dir, \"val\")\n",
    "\n",
    "os.makedirs(train_data_dir, exist_ok=True)\n",
    "os.makedirs(test_data_dir, exist_ok=True)\n",
    "os.makedirs(val_data_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "\n",
    "#%% actions images\n",
    "#####################################################\n",
    "# images\n",
    "\n",
    "# Get the list of action names\n",
    "action_names = os.listdir(ucf_preprocessed_dir_img)\n",
    "\n",
    "# Iterate over each action name\n",
    "for action_name in action_names:\n",
    "    action_dir = os.path.join(ucf_preprocessed_dir_img, action_name)\n",
    "    video_names = os.listdir(action_dir)\n",
    "\n",
    "    # Iterate over each video name\n",
    "    for video_name in video_names:\n",
    "        video_dir = os.path.join(action_dir, video_name)\n",
    "        image_files = os.listdir(video_dir)\n",
    "\n",
    "        # Randomly shuffle the image files\n",
    "        random.shuffle(image_files)\n",
    "\n",
    "        # Calculate the number of images for each split\n",
    "        num_images = len(image_files)\n",
    "        num_train = int(0.7 * num_images)\n",
    "        num_test = int(0.15 * num_images)\n",
    "        num_val = num_images - num_train - num_test\n",
    "\n",
    "        # Split the image files into train, test, and validation sets\n",
    "        train_files = image_files[:num_train]\n",
    "        test_files = image_files[num_train:num_train + num_test]\n",
    "        val_files = image_files[num_train + num_test:]\n",
    "\n",
    "        # Create the action directory in train, test, and validation directories\n",
    "        train_action_dir = os.path.join(train_data_dir, \"images\")\n",
    "        test_action_dir = os.path.join(test_data_dir, \"images\")\n",
    "        val_action_dir = os.path.join(val_data_dir, \"images\")\n",
    "\n",
    "        os.makedirs(train_action_dir, exist_ok=True)\n",
    "        os.makedirs(test_action_dir, exist_ok=True)\n",
    "        os.makedirs(val_action_dir, exist_ok=True)\n",
    "\n",
    "        # Copy the image files to the respective directories\n",
    "        for file in train_files:\n",
    "            src = os.path.join(video_dir, file)\n",
    "            dst = os.path.join(train_action_dir, file)\n",
    "            shutil.copy(src, dst)\n",
    "\n",
    "        for file in test_files:\n",
    "            src = os.path.join(video_dir, file)\n",
    "            dst = os.path.join(test_action_dir, file)\n",
    "            shutil.copy(src, dst)\n",
    "\n",
    "        for file in val_files:\n",
    "            src = os.path.join(video_dir, file)\n",
    "            dst = os.path.join(val_action_dir, file)\n",
    "            shutil.copy(src, dst)\n",
    "\n",
    "\n",
    "#%%\n",
    "#####################################################\n",
    "# labels\n",
    "\n",
    "# Assign actions to labels\n",
    "train_label_dir = os.path.join(train_dir, \"train\")\n",
    "test_label_dir = os.path.join(train_dir, \"test\")\n",
    "val_label_dir = os.path.join(train_dir, \"val\")\n",
    "\n",
    "os.makedirs(train_label_dir, exist_ok=True)\n",
    "os.makedirs(test_label_dir, exist_ok=True)\n",
    "os.makedirs(val_label_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "for action_name in action_names:\n",
    "    action_label_dir = os.path.join(ucf_action_labelled_roi_dir_label, action_name)\n",
    "    video_names = os.listdir(action_label_dir)\n",
    "\n",
    "    # Iterate over each video name\n",
    "    for video_name in video_names:\n",
    "        labels_dir = os.path.join(action_label_dir, video_name, \"predict\", \"labels\")\n",
    "        label_files = os.listdir(labels_dir)\n",
    "\n",
    "        # Split the label files into train, test, and validation sets\n",
    "        train_files = label_files[:num_train]\n",
    "        test_files = label_files[num_train:num_train + num_test]\n",
    "        val_files = label_files[num_train + num_test:]\n",
    "\n",
    "        # Create the action directory in train, test, and validation directories\n",
    "        train_action_dir = os.path.join(train_label_dir, \"labels\")\n",
    "        test_action_dir = os.path.join(test_label_dir, \"labels\")\n",
    "        val_action_dir = os.path.join(val_label_dir, \"labels\")\n",
    "\n",
    "        os.makedirs(train_action_dir, exist_ok=True)\n",
    "        os.makedirs(test_action_dir, exist_ok=True)\n",
    "        os.makedirs(val_action_dir, exist_ok=True)\n",
    "\n",
    "        # Copy the label files to the respective directories\n",
    "        for file in train_files:\n",
    "            src = os.path.join(labels_dir, file)\n",
    "            dst = os.path.join(train_action_dir, file)\n",
    "            shutil.copy(src, dst)\n",
    "\n",
    "        for file in test_files:\n",
    "            src = os.path.join(labels_dir, file)\n",
    "            dst = os.path.join(test_action_dir, file)\n",
    "            shutil.copy(src, dst)\n",
    "\n",
    "        for file in val_files:\n",
    "            src = os.path.join(labels_dir, file)\n",
    "            dst = os.path.join(val_action_dir, file)\n",
    "            shutil.copy(src, dst)\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "# Print the success message\n",
    "print(\"Train-test-val splitting and label assignment completed successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7_action_detection_model_training.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  ACTION DETECTION \n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a model\n",
    "model = YOLO('yolov8n-pose.yaml')  # build a new model from YAML\n",
    "model = YOLO('yolov8n-pose.pt')  # load a pretrained model (recommended for training)\n",
    "model = YOLO('yolov8n-pose.yaml').load('yolov8n-pose.pt')  # build from YAML and transfer weights\n",
    "\n",
    "# Train the model\n",
    "results = model.train(data='action_detection_model_config.yaml', epochs=100, imgsz=640)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
